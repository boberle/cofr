filtered {
  path = cc.fr.300.vec.filtered
  size = 300
}
embeddings {
  path = cc.fr.300.vec
  size = 300
}


# Distributed training configurations.
two_local_gpus {
  addresses {
    ps = [130.79.164.53:2230]
    worker = [130.79.164.53:2228, 130.79.164.33:2229, 130.79.164.52:2235]
  }
  gpus = [0]
}

# Main configuration.
best {
  # Computation limits.
  max_top_antecedents = 50
  max_training_sentences = 50
  top_span_ratio = 0.4

  # Model hyperparameters.
  filter_widths = [3, 4, 5]
  filter_size = 50
  char_embedding_size = 8
  contextualization_size = 200
  contextualization_layers = 3
  ffnn_size = 150
  ffnn_depth = 2
  feature_size = 20
  max_span_width = 30
  use_metadata = true
  use_features = true
  model_heads = true
  coref_depth = 2
  lm_layers = 4
  lm_size = 1024
  coarse_to_fine = true
  refinement_sharing = false

  # Learning hyperparameters.
  max_gradient_norm = 5.0
  lstm_dropout_rate = 0.4
  lexical_dropout_rate = 0.5
  dropout_rate = 0.2
  optimizer = adam
  learning_rate = 0.001
  decay_rate = 1.0
  decay_frequency = 100
  ema_decay = 0.9999

  # Other.
  eval_frequency = 5000
  # eval_frequency = 1
  report_frequency = 100
  log_root = logs
  cluster = ${two_local_gpus}
  multi_gpu = false
  gold_loss = false
  b3_loss = false
  mention_loss = false
  antecedent_loss = true

  # Entity Equalization
  entity_equalization = true
  antecedent_averaging = false
  use_cluster_size = true
  entity_average = false

  # French!
  use_gold_mentions = false
  save_frequency = 100
  include_singletons = false
  eval_for_mentions = false

}

fr_base = ${best} {
  # emb
  char_vocab_path = char_vocab.french.txt
  head_embeddings = ${embeddings}
  context_embeddings = ${embeddings}
  # corpus
  train_path = train.french.jsonlines
  eval_path = dev.french.jsonlines
  # lm
  lm_size = 768
  # ling
  #genres = ["co", "es", "ot", "ub"] # ancor
  genres = ["ge"] # democrat
  include_singletons = true
  # hyper
  # when predicting (must be cased)
  bert_model_path = "multi_cased_L-12_H-768_A-12"
  # debug
  #train_path = short.french.jsonlines
  #eval_path = short.french.jsonlines
  eval_frequency = 6
  report_frequency = 2
  save_frequency = 100
}

fr_mentcoref = ${fr_base} {
  use_gold_mentions = false
  eval_for_mentions = false
  lm_path = bert_features_evaluate.hdf5
}

fr_mentcorefsc = ${fr_base} {
  use_gold_mentions = true
  eval_for_mentions = false
  lm_path = bert_features_evaluate.hdf5
}

fr_coref = ${fr_base} {
  use_gold_mentions = true
  eval_for_mentions = false
  lm_path = bert_features_evaluate.hdf5
}

fr_ment = ${fr_base} {
  use_gold_mentions = false
  eval_for_mentions = true
  lm_path = bert_features_evaluate.hdf5
  mention_loss = true
  antecedent_loss = false
  #top_span_ratio = 0.21 # ancor
  top_span_ratio = 0.27 # democrat
}

train_fr_coref = ${fr_coref} {
  head_embeddings = ${filtered}
  context_embeddings = ${filtered}
  lm_path = bert_features_train.hdf5
}

train_fr_ment = ${fr_ment} {
  head_embeddings = ${filtered}
  context_embeddings = ${filtered}
  lm_path = bert_features_train.hdf5
}

train_fr_mentcoref = ${fr_mentcoref} {
  head_embeddings = ${filtered}
  context_embeddings = ${filtered}
  lm_path = bert_features_train.hdf5
}

